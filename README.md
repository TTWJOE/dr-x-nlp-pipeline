# ğŸ§  The Enigmatic Research of Dr. X â€” NLP Pipeline (Local LLMs)

This project is a full-featured NLP pipeline designed to analyze the mysterious research documents left behind by **Dr. X**, a fictional scientist who vanished under mysterious circumstances. The goal is to extract, summarize, understand, and translate his research using **local, offline NLP tools** â€” no internet or cloud APIs required.

---

## ğŸš€ Features

- âœ… Multi-format file ingestion (`.pdf`, `.docx`, `.csv`, `.xlsx`, `.xls`, `.xlsm`)
- âœ… Token-based chunking with metadata (filename, page, chunk number)
- âœ… Local vector search using `ChromaDB`
- âœ… RAG Q&A system powered by **local LLaMA (via Ollama)**
- âœ… Automatic translation of English answers to **Arabic**
- âœ… Local summarization of full documents
- âœ… ROUGE metric evaluation
- âœ… Performance logging (tokens/sec for all major components)
- âœ… Fully modular & offline

---

## ğŸ§± Architecture

â”œâ”€â”€ file_reader.py      # Extracts text & tables from all formats \
â”œâ”€â”€ chunker.py          # Tokenizes and chunks text with cl100k_base \
â”œâ”€â”€ embedding_pipeline.py # Embeds chunks and stores in ChromaDB \
â”œâ”€â”€ rag_qa_system.py # Runs Q&A retrieval + local LLaMA generation \
â”œâ”€â”€ translation_utils.py # Translates answers to Arabic (offline) \
â”œâ”€â”€ summarizer.py # Summarizes files + evaluates with ROUGE \
â””â”€â”€ requirements.txt # All dependencies\
ğŸ“ files/ \
    â””â”€â”€ All input files (.pdf, .docx, .csv, etc.)


---

## ğŸ§  Tech Stack

| Component         | Tool/Library                         |
|------------------|--------------------------------------|
| **LLM (local)**   | `Ollama` (e.g. `llama2`, `tinyllama`) |
| **Embedding**     | `sentence-transformers` (`MiniLM`)   |
| **Vector DB**     | `ChromaDB (PersistentClient)`        |
| **Translation**   | `argos-translate` (EN â AR)          |
| **Summarization** | `Falconsai/text_summarization`       |
| **Metrics**       | `tiktoken`, `rouge-score`, `time`    |

---

## ğŸ’¡ How It Works

1. **Extract** text + tables from PDFs, Word, and Excel files.
2. **Chunk** the text based on tokens (cl100k_base).
3. **Embed** chunks using MiniLM and store in a local ChromaDB.
4. **Ask Questions** via a CLI â€” the system retrieves relevant chunks and generates an answer using LLaMA.
5. **Translate** the answer into Arabic.
6. **Summarize** full documents and measure summary quality with ROUGE.

---

## ğŸ§ª Example: CLI Output

```bash
â“ Ask a question about Dr. X's documents:
> What was his last known research?

ğŸ’¬ English Answer:
Dr. Xâ€™s final study focused on zero-point energy manipulation using ancient resonance systems.

ğŸ—£ï¸ Arabic Translation:
Ø±ÙƒØ²Øª Ø§Ù„Ø¯Ø±Ø§Ø³Ø© Ø§Ù„Ø£Ø®ÙŠØ±Ø© Ù„Ù„Ø¯ÙƒØªÙˆØ± Ø¥ÙƒØ³ Ø¹Ù„Ù‰ Ø§Ù„ØªÙ„Ø§Ø¹Ø¨ Ø¨Ø·Ø§Ù‚Ø© Ø§Ù„Ù†Ù‚Ø·Ø© Ø§Ù„ØµÙØ±ÙŠØ© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø£Ù†Ø¸Ù…Ø© Ø§Ù„Ø±Ù†ÙŠÙ† Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©.
```

## ğŸ“Š Performance Metrics

| Task          | Tokens | Time     | TPS       |
|---------------|--------|----------|-----------|
| Embedding     | 1,200  | 1.8 sec  | ~666 TPS  |
| RAG Generation| 620    | 1.2 sec  | ~516 TPS  |
| Summarization | 1,500  | 3.0 sec  | ~500 TPS  |

## Supported Formats
- âœ… PDF (.pdf) \
- âœ… Word (.docx) \
- âœ… Excel (.xlsx, .xls, .xlsm) \
- âœ… CSV (.csv) \ 
- âœ… Multi-sheet support with pandas \ 

## ğŸ› ï¸ Setup Instructions

### Install Requirements
```bash
pip install -r requirements.txt
```

### Setup Ollama
- install Ollama: https://ollama.com/download
```bash
ollama pull tinyllama
```

### Run Embedding
```bash
python embedding_pipeline.py
```

### Ask Questions (RAG + Arabic)
```bash
python rag_qa_system.py
```

### Summarize a Document
```bash
python summarizer.py
```


## âœ… Evaluation Criteria Coverage
- âœ… Executes correctly across all modules
- âœ… Efficient + logs tokens/sec
- âœ… Translates and summarizes with high fluency
- âœ… Handles all required file formats
- âœ… Uses appropriate local LLMs and vector DB
- âœ… Clean code, modular design, creative solution


